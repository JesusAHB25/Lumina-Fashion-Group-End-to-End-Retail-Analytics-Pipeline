{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4e65fc1",
   "metadata": {},
   "source": [
    "1. MODULE IMPORTATION: Loading essential libraries for data manipulation, visualization, and database connectivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d934e19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Data manipulation and analysis.\n",
    "import numpy as np # Numerical operations and dependency for pandas.\n",
    "import matplotlib.pyplot as plt # Core plotting library.\n",
    "import seaborn as sns # Advanced statistical data visualization.\n",
    "from sqlalchemy import create_engine # Database engine for SQL connectivity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a31c72c",
   "metadata": {},
   "source": [
    "2. DATA INGESTION: Initializing dataframes from CSV sources and organizing them for batch processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4f8740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading raw data from CSV files using absolute paths.\n",
    "customer_data = pd.read_csv(r'C:\\Users\\MrJes\\OneDrive\\Data Analysis\\End-To-End Projects\\Lumina Fashion Group\\.csv files\\customer_data.csv')\n",
    "product_data = pd.read_csv(r'C:\\Users\\MrJes\\OneDrive\\Data Analysis\\End-To-End Projects\\Lumina Fashion Group\\.csv files\\product_data.csv')\n",
    "sales_data = pd.read_csv(r'C:\\Users\\MrJes\\OneDrive\\Data Analysis\\End-To-End Projects\\Lumina Fashion Group\\.csv files\\sales_data.csv')\n",
    "store_data = pd.read_csv(r'C:\\Users\\MrJes\\OneDrive\\Data Analysis\\End-To-End Projects\\Lumina Fashion Group\\.csv files\\store_data.csv')\n",
    "\n",
    "# Encapsulating dataframes in a dictionary so Python don't repeat itself\n",
    "# logic during the initial assessment and export phases.\n",
    "dataframes = {'customers' : customer_data, \n",
    "              'products' : product_data,\n",
    "              'sales' : sales_data,\n",
    "              'stores' : store_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecff2641",
   "metadata": {},
   "source": [
    "3. AUTOMATED DATA AUDIT: Utilizing loops to perform a rapid assessment of data integrity (schema, null values, and duplicates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8307f102",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, file in dataframes.items():        \n",
    "    print(f'[---] {name} SCHEMA INFO [---]')        \n",
    "    print(f'\\n{file.info()}')                # Displays data types and memory usage.\n",
    "    print('[---] NULL VALUE COUNT [---]')\n",
    "    print(f'\\n{file.isnull().sum()}')        # Identifies missing values per column.\n",
    "    print('[---] DUPLICATE RECORD COUNT [---]')\n",
    "    print(f'\\n{file.duplicated().sum()}')    # Checks for redundant rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3306882d",
   "metadata": {},
   "source": [
    "4. DATABASE INTEGRATION: Establishing a PostgreSQL connection to facilitate advanced data cleaning and complex relational queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1784f135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the SQLAlchemy engine for the local PostgreSQL instance.\n",
    "engine = create_engine('postgresql://postgres:J.e.s.u.s01*@localhost:5432/lumina_fashion_group')\n",
    "\n",
    "# Exporting pandas dataframes to SQL tables to enable relational manipulation.\n",
    "for table_name, df in dataframes.items():   \n",
    "    df.to_sql(table_name, engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b4ea9f",
   "metadata": {},
   "source": [
    "5. ETL PROCESS: Executing a Master Query to join relational tables, handle missing values, and calculate KPIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62dd002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 'master_query' serves as the ETL (Extract, Transform, Load) layer.\n",
    "# It standardizes the data before it reaches the analysis stage to ensure consistency.\n",
    "\n",
    "master_query = \"\"\"\n",
    "SELECT \n",
    "    s.transaction_id,\n",
    "    s.date::DATE, \n",
    "    COALESCE(s.customer_id, 'GUEST-001') as customer_id, \n",
    "    p.season,\n",
    "    st.store_name,\n",
    "    st.region,\n",
    "    p.product_id, \n",
    "    REPLACE(p.category, '???', 'Other') as category, \n",
    "    COALESCE(p.color, 'Unspecified') as color, \n",
    "    p.size,\n",
    "    s.quantity,\n",
    "    p.list_price,\n",
    "    COALESCE(s.discount, 0) as discount_pct, \n",
    "    (s.quantity * p.list_price) * (1 - COALESCE(s.discount, 0)) as net_revenue \n",
    "FROM sales s\n",
    "LEFT JOIN customers c ON s.customer_id = c.customer_id\n",
    "JOIN products p ON s.product_id = p.product_id\n",
    "JOIN stores st ON s.store_id = st.store_id;\n",
    "\"\"\"\n",
    "# Importing the cleaned, joined dataset back into pandas for analysis.\n",
    "master_df = pd.read_sql(master_query, engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89935f9b",
   "metadata": {},
   "source": [
    "6. EXPLORATORY DATA ANALYSIS: Visualizing trends, regional performance, and product attributes to identify business patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02913325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 1: TEMPORAL FEATURE ENGINEERING\n",
    "# Converting 'date' to datetime objects to unlock specialized pandas .dt methods.\n",
    "master_df['date'] = pd.to_datetime(master_df['date'])  \n",
    "master_df['month'] = master_df['date'].dt.month      \n",
    "master_df['year'] = master_df['date'].dt.year        \n",
    "master_df['day_name'] = master_df['date'].dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70276211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 2.1: Seasonal Trends Analysis:\n",
    "\n",
    "# Aggregating revenue by month/year to identify cyclical growth or seasonal declines.\n",
    "yearly_monthly_trend = master_df['net_revenue'].groupby([master_df['year'], master_df['month']]).sum().reset_index()\n",
    "\n",
    "# Visualization: Time-series line plot for revenue growth.\n",
    "sns.set_style('whitegrid')\n",
    "sns.lineplot(data=yearly_monthly_trend, x='month', y='net_revenue', \n",
    "             hue='year', marker='o', palette='YlGnBu') \n",
    "\n",
    "# Plot Customization\n",
    "plt.title('Monthly Total Revenue Trends')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Total Net Revenue')\n",
    "\n",
    "plt.legend(title='Year', loc='upper left')\n",
    "plt.xticks(ticks=range(1,13), labels=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "plt.yticks(ticks=plt.yticks()[0], labels=[f'${int(y/1e3)}K' for y in plt.yticks()[0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307e7490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 2.2: Seasonal Sales Count Analysis:\n",
    "\n",
    "# Assessing sales volume by month and clothing season.\n",
    "seasonal_trend = master_df.groupby(['month', 'season']).size().reset_index(name='sales_count')\n",
    "\n",
    "# Visualization: \n",
    "sns.barplot(data=seasonal_trend, x='month', y='sales_count', hue='season', palette='BuPu')\n",
    "\n",
    "# Plot Customization\n",
    "plt.title('Monthly Sales Volume by Season')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Sales Count')\n",
    "\n",
    "plt.legend(title='Season', loc='lower right')\n",
    "plt.xticks(ticks=range(0,12), labels=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "plt.show()\n",
    "\n",
    "# Insight: December shows high sales volume across all categories, likely driven by holiday shopping, \n",
    "# despite it being the off-season for summer clothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed939375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 3: REGIONAL PERFORMANCE\n",
    "\n",
    "# Sorting is applied here to highlight the top-performing regions immediately in the bar chart.\n",
    "region_performance = master_df['net_revenue'].groupby(master_df['region']).sum().reset_index().sort_values(by='net_revenue', ascending=False)\n",
    "\n",
    "sns.barplot(data=region_performance, x='net_revenue', y='region', hue='region', orient='h', palette='BuPu')\n",
    "\n",
    "plt.title('Total Revenue Contribution by Region')\n",
    "plt.xlabel('Net Revenue')\n",
    "plt.ylabel('Region')\n",
    "plt.xticks(ticks=plt.xticks()[0], labels=[f'${int(x):,}' for x in plt.xticks()[0]], size=8) \n",
    "plt.show()\n",
    "\n",
    "# Observation: The Online channel currently trails physical regions in total revenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22066d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 4.1: Attributes Analysis.\n",
    "\n",
    "# Investigating the relationship between product category and color preferences.\n",
    "attribute_performance = pd.crosstab(master_df['category'], master_df['color'])\n",
    "\n",
    "sns.heatmap(data=attribute_performance, cmap='YlGnBu') \n",
    "\n",
    "plt.xlabel('Color')\n",
    "plt.ylabel('Category')\n",
    "plt.title('Sales Density: Category vs. Color')\n",
    "plt.show()\n",
    "\n",
    "# Observation: White accessories, bottoms, and dresses represent the highest sales density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2e3fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4.2: Discount Impact Analysis.\n",
    "\n",
    "# We use 'median' for quantity to avoid outliers skewing the typical purchase behavior at each discount level.\n",
    "discount_analysis = master_df.groupby('discount_pct').agg({'quantity': 'median', 'net_revenue': 'sum'}).reset_index()\n",
    "discount_analysis = master_df.groupby('discount_pct').agg({'quantity': 'median', 'net_revenue': 'sum'}).reset_index()\n",
    "discount_analysis.columns = ['discount_pct', 'median_quantity', 'total_net_revenue']\n",
    "\n",
    "sns.barplot(data=discount_analysis, x='discount_pct', y='total_net_revenue', hue='discount_pct', palette='YlGnBu')\n",
    "\n",
    "plt.title('Impact of Discount Levels on Total Revenue')\n",
    "plt.xlabel('Discount Percentage')\n",
    "plt.ylabel('Total Net Revenue')\n",
    "plt.xticks(ticks=plt.xticks()[0], labels=[f'{int(x*10)}%' for x in plt.xticks()[0]]) \n",
    "plt.yticks(ticks=plt.yticks()[0], labels=[f'${int(y/1e6)}M' for y in plt.yticks()[0]]) \n",
    "plt.legend(title='Discount %', loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "# Insight: Higher discount brackets do not correlate with a proportional surge in total revenue."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
